---
title: Resources
permalink: /resources/
---


## Datasets
<hr>

### 1. University-1652
![](https://github.com/layumi/University1652-Baseline/raw/master/docs/index_files/Data.jpg)
University-1652 is a multi-view multi-source benchmark for drone-based geo-localization that contains 1652 buildings of 72 universities around the world. We provide images collected from the virtual drone, the satellite and the ground.

[[Paper]](https://arxiv.org/abs/2002.12186)
[[Slide]](http://zdzheng.xyz/ACM-MM-Talk.pdf)
[[Dataset]](https://github.com/layumi/University1652-Baseline)
[[Explore Drone-view Data]](https://github.com/layumi/University1652-Baseline/blob/master/docs/index_files/sample_drone.jpg?raw=true)
[[Explore Satellite-view Data]](https://github.com/layumi/University1652-Baseline/blob/master/docs/index_files/sample_satellite.jpg?raw=true)
[[Explore Street-view Data]](https://github.com/layumi/University1652-Baseline/blob/master/docs/index_files/sample_street.jpg?raw=true)
[[Video Sample]](https://www.youtube.com/embed/dzxXPp8tVn4?vq=hd1080)
[[中文介绍]](https://zhuanlan.zhihu.com/p/110987552)

Task 1: Drone-view target localization. (Drone -> Satellite)} Given one drone-view image or video, the task aims to find the most similar satellite-view image to localize the target building in the satellite view.

Task 2: Drone navigation. (Satellite -> Drone)} Given one satellite-view image, the drone intends to find the most relevant place (drone-view images) that it has passed by. According to its flight history, the drone could be navigated back to the target place.

### 2. DG-Market
![](https://github.com/layumi/DG-Net/blob/gh-pages/index_files/DGMarket-logo.png)

We provide our generated images and make a large-scale synthetic dataset called DG-Market. This dataset is generated by our DG-Net (https://arxiv.org/abs/1904.07223) and consists of 128,307 images (613MB), about 10 times larger than the training set of original Market-1501 (even much more can be generated with DG-Net). It can be used as a source of unlabeled training dataset for semi-supervised learning. You may download the dataset from [Google Drive](https://drive.google.com/file/d/126Gn90Tzpk3zWp2c7OBYPKc-ZjhptKDo/view?usp=sharing) (or [Baidu Disk](https://pan.baidu.com/s/1n4M6s-qvE08J8SOOWtWfgw) password: qxyh).  

|   |  DG-Market   | Market-1501 (training) |
|---|--------------|-------------|
| #identity| 	-   |  751        |
| #images| 128,307 |  12,936     |

### 3. VSPW: A large-scale dataset for video scene parsing in the wild 
![1001623303486_ pic_hd](https://user-images.githubusercontent.com/12868455/121470723-f6d71180-ca01-11eb-93b5-3db9b6305307.jpg)
[[Project Page]](https://www.vspwdataset.com)

1. Large Scale: 251,632 pixel-level annotated frames from 124 categories, 3,536 videos from 231 scenarios (indoor and  outdoor). 
2. Well-trimmed long-temporal clips: a complete shot lasting 5 seconds on average.
3. Dense annotation: The pixel-level annotations are provided at 15 f/s. 
4. High resolution. Over 96% videos are with high resolutions from 720P to 4K.


### 4. Awesome Lists

![](https://camo.githubusercontent.com/1131548cf666e1150ebd2a52f44776d539f06324/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f6d61737465722f6d656469612f6c6f676f2e737667)

- [Awesome Segmentation Domain Adaptation](https://github.com/layumi/Seg-Uncertainty/tree/master/awesome-SegDA)
- [Awesome Vehicle Retrieval](https://github.com/layumi/Vehicle_reID-Collection)
- [Awesome AutoDL](https://github.com/D-X-Y/Awesome-AutoDL)
- [Awesome Fools](https://github.com/layumi/Awesome-Fools)
- [Awesome Geo-localization](https://github.com/layumi/University1652-Baseline/tree/master/State-of-the-art)
